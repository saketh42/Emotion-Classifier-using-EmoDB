# MLproject
In this project, we aim to create a system that can detect human emotions by analyzing both how people speak (through audio) and what they say (through text). By breaking down audio signals into important features like tone and pitch, and examining words through patterns such as frequency and sentiment, we will train models to recognize emotions such as happiness, sadness, and anger. To keep things simple and efficient, we will use four well-known machine learning methods: Support Vector Machines (SVM), Random Forest, Na√Øve Bayes, and K-Nearest Neighbors (KNN). The models will be tested on six different datasets to ensure they work well across various types of data, with metrics like accuracy and F1-score helping us measure how well the system performs.
